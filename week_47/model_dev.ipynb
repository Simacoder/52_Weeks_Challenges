{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ba705fd",
   "metadata": {},
   "source": [
    "A detailed walkthrough of the YOLOv1 architecture and its PyTorch implementation from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874519d8",
   "metadata": {},
   "source": [
    "Importing Packages to run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d60b470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch \n",
    "import torch\n",
    "import torch.nn as nn \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb434043",
   "metadata": {},
   "source": [
    "# define the parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20630bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = 7\n",
    "B = 2\n",
    "C = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ae7d13",
   "metadata": {},
   "source": [
    "I initialized above are the default values given in the paper, in which S represents the number of grid cells along the horizontal and vertical axes, B denotes the number of bounding boxes generated by each cell, and C is the number of classes available in the dataset. Since we use S=7 and B=2, our YOLOv1 will produce7×7×2=98 bounding boxes in total for each image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b770faa1",
   "metadata": {},
   "source": [
    "The Building Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7df9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codeblock 2\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, \n",
    "                 in_channels, \n",
    "                 out_channels, \n",
    "                 kernel_size, \n",
    "                 stride, \n",
    "                 padding, \n",
    "                 maxpool_flag=False):\n",
    "        super().__init__()\n",
    "        self.maxpool_flag = maxpool_flag\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels=in_channels,       #(1)\n",
    "                              out_channels=out_channels, \n",
    "                              kernel_size=kernel_size, \n",
    "                              stride=stride, \n",
    "                              padding=padding)\n",
    "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.1)   #(2)\n",
    "        \n",
    "        if self.maxpool_flag:\n",
    "            self.maxpool = nn.MaxPool2d(kernel_size=2,       #(3)\n",
    "                                        stride=2)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        print(f'original\\t: {x.size()}')\n",
    "\n",
    "        x = self.conv(x)\n",
    "        print(f'after conv\\t: {x.size()}')\n",
    "        \n",
    "        x = self.leaky_relu(x)\n",
    "        print(f'after leaky relu: {x.size()}')\n",
    "        \n",
    "        if self.maxpool_flag:\n",
    "            x = self.maxpool(x)\n",
    "            print(f'after maxpool\\t: {x.size()}')\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0340aeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codeblock 3\n",
    "convblock = ConvBlock(in_channels=3,       #(1)\n",
    "                      out_channels=64,     #(2)\n",
    "                      kernel_size=7,       #(3)\n",
    "                      stride=2,            #(4)\n",
    "                      padding=3,           #(5)\n",
    "                      maxpool_flag=True)   #(6)\n",
    "x = torch.randn(1, 3, 448, 448)            #(7)\n",
    "out = convblock(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae04ce4b",
   "metadata": {},
   "source": [
    "In modern architectures, we normally use the Conv-BN-ReLU structure, but at the time YOLOv1 was created, it seems like batch normalization layer was not quite popular just yet, as it came out only several months before YOLOv1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31452adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codeblock 3\n",
    "convblock = ConvBlock(in_channels=3,       #(1)\n",
    "                      out_channels=64,     #(2)\n",
    "                      kernel_size=7,       #(3)\n",
    "                      stride=2,            #(4)\n",
    "                      padding=3,           #(5)\n",
    "                      maxpool_flag=True)   #(6)\n",
    "x = torch.randn(1, 3, 448, 448)            #(7)\n",
    "out = convblock(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3a31f8",
   "metadata": {},
   "source": [
    "Afterwards, we can simply generate a tensor of random values with the dimension of 1×3×448×448 (#(7)) which simulates a batch of a single RGB image of size 448×448 and then pass it through the network. You can see in the resulting output below that our convolution layer successfully increased the number of channels to 64 and halved the spatial dimension to 224×224. The halving was done once again all the way to 112×112 thanks to the maxpooling layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd370ef",
   "metadata": {},
   "source": [
    "The Backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61c8c665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codeblock 4a\n",
    "class Backbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # in_channels, out_channels, kernel_size, stride, padding\n",
    "        self.stage0 = ConvBlock(3, 64, 7, 2, 3, maxpool_flag=True)      #(1)\n",
    "        self.stage1 = ConvBlock(64, 192, 3, 1, 1, maxpool_flag=True)    #(2)\n",
    "        \n",
    "        self.stage2 = nn.ModuleList([\n",
    "            ConvBlock(192, 128, 1, 1, 0), \n",
    "            ConvBlock(128, 256, 3, 1, 1), \n",
    "            ConvBlock(256, 256, 1, 1, 0),\n",
    "            ConvBlock(256, 512, 3, 1, 1, maxpool_flag=True)      #(3)\n",
    "        ])\n",
    "        \n",
    "        \n",
    "        self.stage3 = nn.ModuleList([])\n",
    "        for _ in range(4):\n",
    "            self.stage3.append(ConvBlock(512, 256, 1, 1, 0))\n",
    "            self.stage3.append(ConvBlock(256, 512, 3, 1, 1))\n",
    "            \n",
    "        self.stage3.append(ConvBlock(512, 512, 1, 1, 0))\n",
    "        self.stage3.append(ConvBlock(512, 1024, 3, 1, 1, maxpool_flag=True))  #(4)\n",
    "        \n",
    "        \n",
    "        self.stage4 = nn.ModuleList([])\n",
    "        for _ in range(2):\n",
    "            self.stage4.append(ConvBlock(1024, 512, 1, 1, 0))\n",
    "            self.stage4.append(ConvBlock(512, 1024, 3, 1, 1))\n",
    "        \n",
    "        self.stage4.append(ConvBlock(1024, 1024, 3, 1, 1))\n",
    "        self.stage4.append(ConvBlock(1024, 1024, 3, 2, 1))    #(5)\n",
    "        \n",
    "        \n",
    "        self.stage5 = nn.ModuleList([])\n",
    "        self.stage5.append(ConvBlock(1024, 1024, 3, 1, 1))\n",
    "        self.stage5.append(ConvBlock(1024, 1024, 3, 1, 1))\n",
    "        \n",
    "# Codeblock 4b\n",
    "    def forward(self, x):\n",
    "        print(f'original\\t: {x.size()}\\n')\n",
    "        \n",
    "        x = self.stage0(x)\n",
    "        print(f'after stage0\\t: {x.size()}\\n')\n",
    "        \n",
    "        x = self.stage1(x)\n",
    "        print(f'after stage1\\t: {x.size()}\\n')\n",
    "        \n",
    "        for i in range(len(self.stage2)):\n",
    "            x = self.stage2[i](x)\n",
    "            print(f'after stage2 #{i}\\t: {x.size()}')\n",
    "        \n",
    "        print()\n",
    "        for i in range(len(self.stage3)):\n",
    "            x = self.stage3[i](x)\n",
    "            print(f'after stage3 #{i}\\t: {x.size()}')\n",
    "        \n",
    "        print()\n",
    "        for i in range(len(self.stage4)):\n",
    "            x = self.stage4[i](x)\n",
    "            print(f'after stage4 #{i}\\t: {x.size()}')\n",
    "        \n",
    "        print()\n",
    "        for i in range(len(self.stage5)):\n",
    "            x = self.stage5[i](x)\n",
    "            print(f'after stage5 #{i}\\t: {x.size()}')\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ad5934",
   "metadata": {},
   "source": [
    "What we do in the above codeblock is to instantiate ConvBlock instances according to the architecture given in the paper. There are several things I want to emphasize here. First, the term stage I use in the code is not explicitly mentioned in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea456e32",
   "metadata": {},
   "source": [
    "let’s verify if our implementation is correct by running the following testing code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff1ca9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original\t: torch.Size([1, 3, 448, 448])\n",
      "\n",
      "original\t: torch.Size([1, 3, 448, 448])\n",
      "after conv\t: torch.Size([1, 64, 224, 224])\n",
      "after leaky relu: torch.Size([1, 64, 224, 224])\n",
      "after maxpool\t: torch.Size([1, 64, 112, 112])\n",
      "after stage0\t: torch.Size([1, 64, 112, 112])\n",
      "\n",
      "original\t: torch.Size([1, 64, 112, 112])\n",
      "after conv\t: torch.Size([1, 192, 112, 112])\n",
      "after leaky relu: torch.Size([1, 192, 112, 112])\n",
      "after maxpool\t: torch.Size([1, 192, 56, 56])\n",
      "after stage1\t: torch.Size([1, 192, 56, 56])\n",
      "\n",
      "original\t: torch.Size([1, 192, 56, 56])\n",
      "after conv\t: torch.Size([1, 128, 56, 56])\n",
      "after leaky relu: torch.Size([1, 128, 56, 56])\n",
      "after stage2 #0\t: torch.Size([1, 128, 56, 56])\n",
      "original\t: torch.Size([1, 128, 56, 56])\n",
      "after conv\t: torch.Size([1, 256, 56, 56])\n",
      "after leaky relu: torch.Size([1, 256, 56, 56])\n",
      "after stage2 #1\t: torch.Size([1, 256, 56, 56])\n",
      "original\t: torch.Size([1, 256, 56, 56])\n",
      "after conv\t: torch.Size([1, 256, 56, 56])\n",
      "after leaky relu: torch.Size([1, 256, 56, 56])\n",
      "after stage2 #2\t: torch.Size([1, 256, 56, 56])\n",
      "original\t: torch.Size([1, 256, 56, 56])\n",
      "after conv\t: torch.Size([1, 512, 56, 56])\n",
      "after leaky relu: torch.Size([1, 512, 56, 56])\n",
      "after maxpool\t: torch.Size([1, 512, 28, 28])\n",
      "after stage2 #3\t: torch.Size([1, 512, 28, 28])\n",
      "\n",
      "original\t: torch.Size([1, 512, 28, 28])\n",
      "after conv\t: torch.Size([1, 256, 28, 28])\n",
      "after leaky relu: torch.Size([1, 256, 28, 28])\n",
      "after stage3 #0\t: torch.Size([1, 256, 28, 28])\n",
      "original\t: torch.Size([1, 256, 28, 28])\n",
      "after conv\t: torch.Size([1, 512, 28, 28])\n",
      "after leaky relu: torch.Size([1, 512, 28, 28])\n",
      "after stage3 #1\t: torch.Size([1, 512, 28, 28])\n",
      "original\t: torch.Size([1, 512, 28, 28])\n",
      "after conv\t: torch.Size([1, 256, 28, 28])\n",
      "after leaky relu: torch.Size([1, 256, 28, 28])\n",
      "after stage3 #2\t: torch.Size([1, 256, 28, 28])\n",
      "original\t: torch.Size([1, 256, 28, 28])\n",
      "after conv\t: torch.Size([1, 512, 28, 28])\n",
      "after leaky relu: torch.Size([1, 512, 28, 28])\n",
      "after stage3 #3\t: torch.Size([1, 512, 28, 28])\n",
      "original\t: torch.Size([1, 512, 28, 28])\n",
      "after conv\t: torch.Size([1, 256, 28, 28])\n",
      "after leaky relu: torch.Size([1, 256, 28, 28])\n",
      "after stage3 #4\t: torch.Size([1, 256, 28, 28])\n",
      "original\t: torch.Size([1, 256, 28, 28])\n",
      "after conv\t: torch.Size([1, 512, 28, 28])\n",
      "after leaky relu: torch.Size([1, 512, 28, 28])\n",
      "after stage3 #5\t: torch.Size([1, 512, 28, 28])\n",
      "original\t: torch.Size([1, 512, 28, 28])\n",
      "after conv\t: torch.Size([1, 256, 28, 28])\n",
      "after leaky relu: torch.Size([1, 256, 28, 28])\n",
      "after stage3 #6\t: torch.Size([1, 256, 28, 28])\n",
      "original\t: torch.Size([1, 256, 28, 28])\n",
      "after conv\t: torch.Size([1, 512, 28, 28])\n",
      "after leaky relu: torch.Size([1, 512, 28, 28])\n",
      "after stage3 #7\t: torch.Size([1, 512, 28, 28])\n",
      "original\t: torch.Size([1, 512, 28, 28])\n",
      "after conv\t: torch.Size([1, 512, 28, 28])\n",
      "after leaky relu: torch.Size([1, 512, 28, 28])\n",
      "after stage3 #8\t: torch.Size([1, 512, 28, 28])\n",
      "original\t: torch.Size([1, 512, 28, 28])\n",
      "after conv\t: torch.Size([1, 1024, 28, 28])\n",
      "after leaky relu: torch.Size([1, 1024, 28, 28])\n",
      "after maxpool\t: torch.Size([1, 1024, 14, 14])\n",
      "after stage3 #9\t: torch.Size([1, 1024, 14, 14])\n",
      "\n",
      "original\t: torch.Size([1, 1024, 14, 14])\n",
      "after conv\t: torch.Size([1, 512, 14, 14])\n",
      "after leaky relu: torch.Size([1, 512, 14, 14])\n",
      "after stage4 #0\t: torch.Size([1, 512, 14, 14])\n",
      "original\t: torch.Size([1, 512, 14, 14])\n",
      "after conv\t: torch.Size([1, 1024, 14, 14])\n",
      "after leaky relu: torch.Size([1, 1024, 14, 14])\n",
      "after stage4 #1\t: torch.Size([1, 1024, 14, 14])\n",
      "original\t: torch.Size([1, 1024, 14, 14])\n",
      "after conv\t: torch.Size([1, 512, 14, 14])\n",
      "after leaky relu: torch.Size([1, 512, 14, 14])\n",
      "after stage4 #2\t: torch.Size([1, 512, 14, 14])\n",
      "original\t: torch.Size([1, 512, 14, 14])\n",
      "after conv\t: torch.Size([1, 1024, 14, 14])\n",
      "after leaky relu: torch.Size([1, 1024, 14, 14])\n",
      "after stage4 #3\t: torch.Size([1, 1024, 14, 14])\n",
      "original\t: torch.Size([1, 1024, 14, 14])\n",
      "after conv\t: torch.Size([1, 1024, 14, 14])\n",
      "after leaky relu: torch.Size([1, 1024, 14, 14])\n",
      "after stage4 #4\t: torch.Size([1, 1024, 14, 14])\n",
      "original\t: torch.Size([1, 1024, 14, 14])\n",
      "after conv\t: torch.Size([1, 1024, 7, 7])\n",
      "after leaky relu: torch.Size([1, 1024, 7, 7])\n",
      "after stage4 #5\t: torch.Size([1, 1024, 7, 7])\n",
      "\n",
      "original\t: torch.Size([1, 1024, 7, 7])\n",
      "after conv\t: torch.Size([1, 1024, 7, 7])\n",
      "after leaky relu: torch.Size([1, 1024, 7, 7])\n",
      "after stage5 #0\t: torch.Size([1, 1024, 7, 7])\n",
      "original\t: torch.Size([1, 1024, 7, 7])\n",
      "after conv\t: torch.Size([1, 1024, 7, 7])\n",
      "after leaky relu: torch.Size([1, 1024, 7, 7])\n",
      "after stage5 #1\t: torch.Size([1, 1024, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "# Codeblock 5\n",
    "backbone = Backbone()\n",
    "x = torch.randn(1, 3, 448, 448)\n",
    "out = backbone(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af93a91",
   "metadata": {},
   "source": [
    "The Fully-Connected Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "381cabf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codeblock 6\n",
    "class FullyConnected(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear0 = nn.Linear(in_features=1024*7*7, out_features=4096)   #(1)\n",
    "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.1)                  #(2)\n",
    "        self.dropout = nn.Dropout(p=0.5)                                    #(3)\n",
    "        self.linear1 = nn.Linear(in_features=4096, out_features=(C+B*5)*S*S)#(4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print(f'original\\t: {x.size()}')\n",
    "        \n",
    "        x = self.linear0(x)\n",
    "        print(f'after linear0\\t: {x.size()}')\n",
    "        \n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.linear1(x)\n",
    "        print(f'after linear1\\t: {x.size()}')\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66fbe39",
   "metadata": {},
   "source": [
    "how the tensor transforms as it is processed by the stack of linear layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "480316c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original\t: torch.Size([1, 50176])\n",
      "after linear0\t: torch.Size([1, 4096])\n",
      "after linear1\t: torch.Size([1, 1470])\n"
     ]
    }
   ],
   "source": [
    "# Codeblock 7\n",
    "fc = FullyConnected()\n",
    "x = torch.randn(1, 1024*7*7)\n",
    "out = fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf68bfc6",
   "metadata": {},
   "source": [
    "We can see in the above output that the fc block takes an input of shape 50176, which is essentially the flattened 1024×7×7 tensor. The linear0 layer works by mapping this input into 4096-dimensional vector, and then the linear1 layer eventually maps it further to 1470. Later in the post-processing stage we need to reshape it to 30×7×7 so that we can take the bounding box and the object classification results easily. Technically speaking, this reshaping process can be done either internally by the model or outside the model. For the sake of simplicity, I decided to leave the output flattened, meaning the reshaping will be handled externally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc9abaf",
   "metadata": {},
   "source": [
    "Connecting the FC Part to the Backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "967358db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codeblock 8\n",
    "class YOLOv1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.backbone = Backbone()\n",
    "        self.fc = FullyConnected()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = torch.flatten(x, start_dim=1)    #(1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c972fd",
   "metadata": {},
   "source": [
    "In order to test our model, we can simply instantiate the YOLOv1 model and pass a dummy tensor that simulates an RGB image of size 448×448 (#(1)). After feeding the tensor into the network (#(2)), I also try to simulate the post-processing step by reshaping the output tensor to 30×7×7 as shown at line #(3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "730e5c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original\t: torch.Size([1, 3, 448, 448])\n",
      "\n",
      "original\t: torch.Size([1, 3, 448, 448])\n",
      "after conv\t: torch.Size([1, 64, 224, 224])\n",
      "after leaky relu: torch.Size([1, 64, 224, 224])\n",
      "after maxpool\t: torch.Size([1, 64, 112, 112])\n",
      "after stage0\t: torch.Size([1, 64, 112, 112])\n",
      "\n",
      "original\t: torch.Size([1, 64, 112, 112])\n",
      "after conv\t: torch.Size([1, 192, 112, 112])\n",
      "after leaky relu: torch.Size([1, 192, 112, 112])\n",
      "after maxpool\t: torch.Size([1, 192, 56, 56])\n",
      "after stage1\t: torch.Size([1, 192, 56, 56])\n",
      "\n",
      "original\t: torch.Size([1, 192, 56, 56])\n",
      "after conv\t: torch.Size([1, 128, 56, 56])\n",
      "after leaky relu: torch.Size([1, 128, 56, 56])\n",
      "after stage2 #0\t: torch.Size([1, 128, 56, 56])\n",
      "original\t: torch.Size([1, 128, 56, 56])\n",
      "after conv\t: torch.Size([1, 256, 56, 56])\n",
      "after leaky relu: torch.Size([1, 256, 56, 56])\n",
      "after stage2 #1\t: torch.Size([1, 256, 56, 56])\n",
      "original\t: torch.Size([1, 256, 56, 56])\n",
      "after conv\t: torch.Size([1, 256, 56, 56])\n",
      "after leaky relu: torch.Size([1, 256, 56, 56])\n",
      "after stage2 #2\t: torch.Size([1, 256, 56, 56])\n",
      "original\t: torch.Size([1, 256, 56, 56])\n",
      "after conv\t: torch.Size([1, 512, 56, 56])\n",
      "after leaky relu: torch.Size([1, 512, 56, 56])\n",
      "after maxpool\t: torch.Size([1, 512, 28, 28])\n",
      "after stage2 #3\t: torch.Size([1, 512, 28, 28])\n",
      "\n",
      "original\t: torch.Size([1, 512, 28, 28])\n",
      "after conv\t: torch.Size([1, 256, 28, 28])\n",
      "after leaky relu: torch.Size([1, 256, 28, 28])\n",
      "after stage3 #0\t: torch.Size([1, 256, 28, 28])\n",
      "original\t: torch.Size([1, 256, 28, 28])\n",
      "after conv\t: torch.Size([1, 512, 28, 28])\n",
      "after leaky relu: torch.Size([1, 512, 28, 28])\n",
      "after stage3 #1\t: torch.Size([1, 512, 28, 28])\n",
      "original\t: torch.Size([1, 512, 28, 28])\n",
      "after conv\t: torch.Size([1, 256, 28, 28])\n",
      "after leaky relu: torch.Size([1, 256, 28, 28])\n",
      "after stage3 #2\t: torch.Size([1, 256, 28, 28])\n",
      "original\t: torch.Size([1, 256, 28, 28])\n",
      "after conv\t: torch.Size([1, 512, 28, 28])\n",
      "after leaky relu: torch.Size([1, 512, 28, 28])\n",
      "after stage3 #3\t: torch.Size([1, 512, 28, 28])\n",
      "original\t: torch.Size([1, 512, 28, 28])\n",
      "after conv\t: torch.Size([1, 256, 28, 28])\n",
      "after leaky relu: torch.Size([1, 256, 28, 28])\n",
      "after stage3 #4\t: torch.Size([1, 256, 28, 28])\n",
      "original\t: torch.Size([1, 256, 28, 28])\n",
      "after conv\t: torch.Size([1, 512, 28, 28])\n",
      "after leaky relu: torch.Size([1, 512, 28, 28])\n",
      "after stage3 #5\t: torch.Size([1, 512, 28, 28])\n",
      "original\t: torch.Size([1, 512, 28, 28])\n",
      "after conv\t: torch.Size([1, 256, 28, 28])\n",
      "after leaky relu: torch.Size([1, 256, 28, 28])\n",
      "after stage3 #6\t: torch.Size([1, 256, 28, 28])\n",
      "original\t: torch.Size([1, 256, 28, 28])\n",
      "after conv\t: torch.Size([1, 512, 28, 28])\n",
      "after leaky relu: torch.Size([1, 512, 28, 28])\n",
      "after stage3 #7\t: torch.Size([1, 512, 28, 28])\n",
      "original\t: torch.Size([1, 512, 28, 28])\n",
      "after conv\t: torch.Size([1, 512, 28, 28])\n",
      "after leaky relu: torch.Size([1, 512, 28, 28])\n",
      "after stage3 #8\t: torch.Size([1, 512, 28, 28])\n",
      "original\t: torch.Size([1, 512, 28, 28])\n",
      "after conv\t: torch.Size([1, 1024, 28, 28])\n",
      "after leaky relu: torch.Size([1, 1024, 28, 28])\n",
      "after maxpool\t: torch.Size([1, 1024, 14, 14])\n",
      "after stage3 #9\t: torch.Size([1, 1024, 14, 14])\n",
      "\n",
      "original\t: torch.Size([1, 1024, 14, 14])\n",
      "after conv\t: torch.Size([1, 512, 14, 14])\n",
      "after leaky relu: torch.Size([1, 512, 14, 14])\n",
      "after stage4 #0\t: torch.Size([1, 512, 14, 14])\n",
      "original\t: torch.Size([1, 512, 14, 14])\n",
      "after conv\t: torch.Size([1, 1024, 14, 14])\n",
      "after leaky relu: torch.Size([1, 1024, 14, 14])\n",
      "after stage4 #1\t: torch.Size([1, 1024, 14, 14])\n",
      "original\t: torch.Size([1, 1024, 14, 14])\n",
      "after conv\t: torch.Size([1, 512, 14, 14])\n",
      "after leaky relu: torch.Size([1, 512, 14, 14])\n",
      "after stage4 #2\t: torch.Size([1, 512, 14, 14])\n",
      "original\t: torch.Size([1, 512, 14, 14])\n",
      "after conv\t: torch.Size([1, 1024, 14, 14])\n",
      "after leaky relu: torch.Size([1, 1024, 14, 14])\n",
      "after stage4 #3\t: torch.Size([1, 1024, 14, 14])\n",
      "original\t: torch.Size([1, 1024, 14, 14])\n",
      "after conv\t: torch.Size([1, 1024, 14, 14])\n",
      "after leaky relu: torch.Size([1, 1024, 14, 14])\n",
      "after stage4 #4\t: torch.Size([1, 1024, 14, 14])\n",
      "original\t: torch.Size([1, 1024, 14, 14])\n",
      "after conv\t: torch.Size([1, 1024, 7, 7])\n",
      "after leaky relu: torch.Size([1, 1024, 7, 7])\n",
      "after stage4 #5\t: torch.Size([1, 1024, 7, 7])\n",
      "\n",
      "original\t: torch.Size([1, 1024, 7, 7])\n",
      "after conv\t: torch.Size([1, 1024, 7, 7])\n",
      "after leaky relu: torch.Size([1, 1024, 7, 7])\n",
      "after stage5 #0\t: torch.Size([1, 1024, 7, 7])\n",
      "original\t: torch.Size([1, 1024, 7, 7])\n",
      "after conv\t: torch.Size([1, 1024, 7, 7])\n",
      "after leaky relu: torch.Size([1, 1024, 7, 7])\n",
      "after stage5 #1\t: torch.Size([1, 1024, 7, 7])\n",
      "original\t: torch.Size([1, 50176])\n",
      "after linear0\t: torch.Size([1, 4096])\n",
      "after linear1\t: torch.Size([1, 1470])\n"
     ]
    }
   ],
   "source": [
    "# Codeblock 9\n",
    "yolov1 = YOLOv1()\n",
    "x = torch.randn(1, 3, 448, 448)      #(1)\n",
    "\n",
    "out = yolov1(x)                      #(2)\n",
    "out = out.reshape(-1, C+B*5, S, S)   #(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954da871",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
